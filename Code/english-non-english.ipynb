{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\ntqdm.pandas()\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nos.chdir('/kaggle/input/')\n\nfrom sklearn.neighbors import NearestNeighbors\nimport torch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-05T19:30:59.460223Z","iopub.execute_input":"2023-03-05T19:30:59.460926Z","iopub.status.idle":"2023-03-05T19:31:00.867212Z","shell.execute_reply.started":"2023-03-05T19:30:59.460883Z","shell.execute_reply":"2023-03-05T19:31:00.866111Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModel\n%env TOKENIZERS_PARALLELISM=true\n\ntop_n = 10\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel_paths = ['/kaggle/input/paraphrasemultilingualmpnetbasev2','/kaggle/input/d/tomoyayanagi/all-minilm-l6-v2']","metadata":{"execution":{"iopub.status.busy":"2023-03-05T19:33:50.658928Z","iopub.execute_input":"2023-03-05T19:33:50.659327Z","iopub.status.idle":"2023-03-05T19:33:50.668051Z","shell.execute_reply.started":"2023-03-05T19:33:50.659294Z","shell.execute_reply":"2023-03-05T19:33:50.665870Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"env: TOKENIZERS_PARALLELISM=true\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load the datasets\ntopics_df = pd.read_csv(\"learning-equality-curriculum-recommendations/topics.csv\")\ncontent_df = pd.read_csv(\"learning-equality-curriculum-recommendations/content.csv\")\ncorr_df = pd.read_csv(\"learning-equality-curriculum-recommendations/correlations.csv\")\nsubmission = pd.read_csv(\"learning-equality-curriculum-recommendations/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-03-05T19:31:05.821457Z","iopub.execute_input":"2023-03-05T19:31:05.822084Z","iopub.status.idle":"2023-03-05T19:31:20.051913Z","shell.execute_reply.started":"2023-03-05T19:31:05.822054Z","shell.execute_reply":"2023-03-05T19:31:20.050859Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"content_df.columns = [\"content_\"+ column for column in content_df.columns]\n\ncorr_df['content_ids'] = corr_df['content_ids'].str.split()\ncorr_df = corr_df.explode('content_ids').reset_index(drop = True)\ncorr_df = corr_df.rename(columns = {'content_ids':'content_id'})\ncorr_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-05T19:31:20.055221Z","iopub.execute_input":"2023-03-05T19:31:20.055616Z","iopub.status.idle":"2023-03-05T19:31:20.437938Z","shell.execute_reply.started":"2023-03-05T19:31:20.055578Z","shell.execute_reply":"2023-03-05T19:31:20.436952Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"         topic_id      content_id\n0  t_00004da3a1b2  c_1108dd0c7a5d\n1  t_00004da3a1b2  c_376c5a8eb028\n2  t_00004da3a1b2  c_5bc0e1e2cba0\n3  t_00004da3a1b2  c_76231f9d0b5e\n4  t_00068291e9a4  c_639ea2ef9c95","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>topic_id</th>\n      <th>content_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>t_00004da3a1b2</td>\n      <td>c_1108dd0c7a5d</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>t_00004da3a1b2</td>\n      <td>c_376c5a8eb028</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>t_00004da3a1b2</td>\n      <td>c_5bc0e1e2cba0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>t_00004da3a1b2</td>\n      <td>c_76231f9d0b5e</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>t_00068291e9a4</td>\n      <td>c_639ea2ef9c95</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"topics_df_topic_tree = pd.DataFrame()\n\nfor channel in tqdm(topics_df[\"channel\"].unique()):\n    channel_df = topics_df[(topics_df[\"channel\"] == channel)].reset_index(drop = True)\n    for level in sorted(channel_df.level.unique()):\n        \n        #For level 0, it first creates a topic tree column which is the title of that topic.            \n        if level == 0:\n            topic_tree = channel_df[channel_df[\"level\"] == level][\"title\"].astype(str)\n            topic_tree_df = pd.DataFrame([channel_df[channel_df[\"level\"] == level][[\"id\"]],topic_tree.values]).T\n            topic_tree_df.columns = [\"child_id\",\"topic_tree\"]\n            channel_df = channel_df.merge(topic_tree_df, left_on = \"id\", right_on = \"child_id\", how = \"left\").drop([\"child_id\"], axis = 1)\n        \n        #Once the topic tree column has been created, the parent node and child node is merged on parent_id = child_id\n        topic_df_parent = channel_df[channel_df[\"level\"] == level][[\"id\",\"title\",\"parent\",\"topic_tree\"]]\n        topic_df_parent.columns = \"parent_\" + topic_df_parent.columns\n        \n        topic_df_child = channel_df[channel_df[\"level\"] == level + 1][[\"id\",\"title\",\"parent\",\"topic_tree\"]]\n        topic_df_child.columns = \"child_\" + topic_df_child.columns\n        \n        topic_df_merged = topic_df_parent.merge(topic_df_child, left_on = \"parent_id\", right_on = \"child_parent\")[[\"child_id\",\"parent_id\",\"parent_title\",\"child_title\",\"parent_topic_tree\"]]\n\n        #Topic tree is parent topic tree + title of the current child on that level\n        topic_tree = topic_df_merged[\"parent_topic_tree\"].astype(str) + \" is the parent of \" + topic_df_merged[\"child_title\"].astype(str)\n        \n        topic_tree_df = pd.DataFrame([topic_df_merged[\"child_id\"].values,topic_tree.values]).T\n        topic_tree_df.columns = [\"child_id\",\"topic_tree\"]\n        \n        channel_df = channel_df.merge(topic_tree_df, left_on = \"id\", right_on = \"child_id\", how = \"left\").drop([\"child_id\"], axis = 1)\n        if \"topic_tree_y\" in list(channel_df.columns):\n            channel_df[\"topic_tree\"] = channel_df[\"topic_tree_x\"].combine_first(channel_df[\"topic_tree_y\"])\n            channel_df = channel_df.drop([\"topic_tree_x\",\"topic_tree_y\"], axis = 1)\n        \n    topics_df_topic_tree = pd.concat([topics_df_topic_tree,channel_df])\n\ntopics_df_topic_tree = topics_df_topic_tree.reset_index(drop = True)\n\ntopics_df_topic_tree.columns = [\"topic_\"+ column for column in topics_df_topic_tree.columns]\ntopics_df_topic_tree = topics_df_topic_tree.rename(columns = {\"topic_topic_tree\":\"topic_tree\"})","metadata":{"execution":{"iopub.status.busy":"2023-03-05T19:31:20.439754Z","iopub.execute_input":"2023-03-05T19:31:20.440169Z","iopub.status.idle":"2023-03-05T19:31:35.242150Z","shell.execute_reply.started":"2023-03-05T19:31:20.440129Z","shell.execute_reply":"2023-03-05T19:31:35.240911Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"100%|██████████| 171/171 [00:14<00:00, 11.61it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"import re\ndef clean_text(text):\n    text = str(text).lower()\n    text = re.sub('\\[.*?@\\]', '', text)\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?@>+', '', text)\n    text = re.sub('\\n', ' ', text)\n    text = re.sub('\\@', '', text)\n    text = re.sub('\\_', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text","metadata":{"execution":{"iopub.status.busy":"2023-03-05T19:31:35.243881Z","iopub.execute_input":"2023-03-05T19:31:35.244297Z","iopub.status.idle":"2023-03-05T19:31:35.251220Z","shell.execute_reply.started":"2023-03-05T19:31:35.244257Z","shell.execute_reply":"2023-03-05T19:31:35.249922Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"topics_df_topic_tree[\"topic_description\"] = (topics_df_topic_tree[\"topic_description\"].fillna(\"\") + \". \" + topics_df_topic_tree[\"topic_tree\"].fillna(\"\")).progress_apply(clean_text)\ncontent_df[\"content_description\"] = (content_df[\"content_title\"].fillna(\"\") + \". \" + content_df[\"content_description\"].fillna(\"\") + \". \" + content_df[\"content_text\"].fillna(\"\")).progress_apply(clean_text)","metadata":{"execution":{"iopub.status.busy":"2023-03-05T19:31:35.253136Z","iopub.execute_input":"2023-03-05T19:31:35.253845Z","iopub.status.idle":"2023-03-05T19:33:32.606233Z","shell.execute_reply.started":"2023-03-05T19:31:35.253805Z","shell.execute_reply":"2023-03-05T19:33:32.605238Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"100%|██████████| 76972/76972 [00:04<00:00, 18157.81it/s]\n100%|██████████| 154047/154047 [01:51<00:00, 1378.73it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"#Mean Pooling - Take attention mask into account for correct averaging\ndef mean_pooling(model_output, attention_mask):\n    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n    return (sum_embeddings / sum_mask).squeeze(0).cpu().numpy()\n\ndef get_embeddings(tokenizer, model, sentences):\n        \n    embeddings = []\n    for sentence in tqdm(sentences):\n        encoded_input = tokenizer(sentence, padding=True, truncation=True, max_length=128, return_tensors='pt').to(device)\n        with torch.no_grad():\n            model_output = model(**encoded_input)\n\n        #Perform pooling. In this case, mean pooling\n        vec = mean_pooling(model_output, encoded_input['attention_mask'])    \n        embeddings.append(vec)\n    return embeddings","metadata":{"execution":{"iopub.status.busy":"2023-03-05T19:33:32.608509Z","iopub.execute_input":"2023-03-05T19:33:32.608914Z","iopub.status.idle":"2023-03-05T19:33:32.617199Z","shell.execute_reply.started":"2023-03-05T19:33:32.608873Z","shell.execute_reply":"2023-03-05T19:33:32.615907Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model_en = AutoModel.from_pretrained(model_paths[1])\nmodel_en.eval()\nmodel_en.to(device)\ntokenizer_en = AutoTokenizer.from_pretrained(model_paths[1])\n\nmodel_not_en = AutoModel.from_pretrained(model_paths[0])\nmodel_not_en.eval()\nmodel_not_en.to(device)\ntokenizer_not_en = AutoTokenizer.from_pretrained(model_paths[0])","metadata":{"execution":{"iopub.status.busy":"2023-03-05T19:33:54.854959Z","iopub.execute_input":"2023-03-05T19:33:54.855677Z","iopub.status.idle":"2023-03-05T19:34:03.722422Z","shell.execute_reply.started":"2023-03-05T19:33:54.855640Z","shell.execute_reply":"2023-03-05T19:34:03.721096Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"%%time\nenglish_content_df = content_df[content_df['content_language'] == 'en'].reset_index(drop = True)\nenglish_content = list(english_content_df[\"content_description\"].values)\n\nother_than_english_content_df = content_df[content_df['content_language'] != 'en'].reset_index(drop = True)\nother_than_english_content = list(other_than_english_content_df[\"content_description\"].values)\n\ncontent_vectors_en = get_embeddings(tokenizer_en, model_en, english_content)\ncontent_vectors_not_en = get_embeddings(tokenizer_not_en, model_not_en, other_than_english_content)\n\nenglish_content_ids = list(english_content_df[\"content_id\"].values)\nother_than_english_content_ids = list(other_than_english_content_df[\"content_id\"].values)","metadata":{"execution":{"iopub.status.busy":"2023-03-05T19:35:02.650406Z","iopub.execute_input":"2023-03-05T19:35:02.650802Z","iopub.status.idle":"2023-03-05T20:05:59.012053Z","shell.execute_reply.started":"2023-03-05T19:35:02.650765Z","shell.execute_reply":"2023-03-05T20:05:59.010753Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"100%|██████████| 65939/65939 [10:13<00:00, 107.44it/s]\n100%|██████████| 88108/88108 [20:42<00:00, 70.92it/s] ","output_type":"stream"},{"name":"stdout","text":"CPU times: user 30min 40s, sys: 20.1 s, total: 31min\nWall time: 30min 56s\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\nnbrs_en = NearestNeighbors(n_neighbors = 50, metric = 'cosine').fit(content_vectors_en)\nnbrs_not_en = NearestNeighbors(n_neighbors = 50, metric = 'cosine').fit(content_vectors_not_en)","metadata":{"execution":{"iopub.status.busy":"2023-03-05T20:07:19.840244Z","iopub.execute_input":"2023-03-05T20:07:19.840762Z","iopub.status.idle":"2023-03-05T20:07:20.238322Z","shell.execute_reply.started":"2023-03-05T20:07:19.840721Z","shell.execute_reply":"2023-03-05T20:07:20.236483Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"CPU times: user 300 ms, sys: 87.8 ms, total: 388 ms\nWall time: 390 ms\n","output_type":"stream"}]},{"cell_type":"code","source":"# calculate the mean F2 over submission topics\nf2_scores = []\nsubmission_topics = list(submission.topic_id.values)\n\nfor submission_topic in tqdm(submission_topics):\n    \n    topic_index = topics_df_topic_tree[topics_df_topic_tree['topic_id'] == submission_topic].index.values[0]\n    tlang = topics_df_topic_tree[topics_df_topic_tree['topic_id'] == submission_topic]['topic_language'].values[0]\n    topic_description = topics_df_topic_tree[topics_df_topic_tree['topic_id'] == submission_topic]['topic_description'].values[0]\n    \n    if tlang == 'en':\n\n        topic_vector = get_embeddings(tokenizer_en, model_en, [topic_description])\n    \n        # calculate the nearest neighbors for the target topic\n        dist, nb = nbrs_en.kneighbors(topic_vector)\n        \n        # get the set of content IDs returned by the nearest neighbors model\n        # (skipping over any content items where the language does not match)\n        pred_content_ids = []\n        for cindex in nb[0]:\n            cid = english_content_ids[cindex]\n            clang = english_content_df[english_content_df['content_id'] == cid]['content_language'].values[0]\n            if clang == tlang:\n                pred_content_ids.append(cid)\n                \n    else:\n        topic_vector = get_embeddings(tokenizer_not_en, model_not_en, [topic_description])\n    \n        # calculate the nearest neighbors for the target topic\n        dist, nb = nbrs_not_en.kneighbors(topic_vector)\n        \n        # get the set of content IDs returned by the nearest neighbors model\n        # (skipping over any content items where the language does not match)\n        pred_content_ids = []\n        for cindex in nb[0]:\n            cid = other_than_english_content_ids[cindex]\n            clang = other_than_english_content_df[other_than_english_content_df['content_id'] == cid]['content_language'].values[0]\n            if clang == tlang:\n                pred_content_ids.append(cid)\n        \n\n    # trim to only the top 20 results\n    pred_content_ids = set(pred_content_ids[:top_n])\n\n    pred_col = ' '.join([pred_content_id for pred_content_id in list(pred_content_ids)])\n    submission.loc[submission['topic_id'] == submission_topic,'content_ids'] = pred_col\n\n    # get the set of ground truth content IDs correlated to the target topic\n    true_content_ids = set(corr_df.loc[corr_df['topic_id'] == submission_topic,'content_id'])\n    \n    \n    # calculate the confusion matrix variables\n    tp = len(true_content_ids.intersection(pred_content_ids))\n    fp = len(pred_content_ids - true_content_ids)\n    fn = len(true_content_ids - pred_content_ids)\n\n    # calculate the F2 score\n    if len(true_content_ids) != 0:        \n        if pred_content_ids:\n            precision = tp / (tp + fp)\n            recall = tp / (tp + fn)\n            f2 = tp / (tp + 0.2 * fp + 0.8*fn)\n        else:\n            f2 = 0\n    else:\n        f2 = 0\n\n    f2_scores.append(f2)\n    \nprint(\"Average F2:\", np.mean(f2_scores))","metadata":{"execution":{"iopub.status.busy":"2023-03-05T20:07:23.749632Z","iopub.execute_input":"2023-03-05T20:07:23.750181Z","iopub.status.idle":"2023-03-05T20:07:28.160876Z","shell.execute_reply.started":"2023-03-05T20:07:23.750138Z","shell.execute_reply":"2023-03-05T20:07:28.159157Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"  0%|          | 0/5 [00:00<?, ?it/s]\n100%|██████████| 1/1 [00:00<00:00, 65.27it/s]\n 20%|██        | 1/5 [00:00<00:03,  1.13it/s]\n100%|██████████| 1/1 [00:00<00:00, 64.25it/s]\n 40%|████      | 2/5 [00:02<00:03,  1.07s/it]\n100%|██████████| 1/1 [00:00<00:00, 84.07it/s]\n 60%|██████    | 3/5 [00:02<00:01,  1.04it/s]\n100%|██████████| 1/1 [00:00<00:00, 69.50it/s]\n 80%|████████  | 4/5 [00:03<00:00,  1.09it/s]\n100%|██████████| 1/1 [00:00<00:00, 68.65it/s]\n100%|██████████| 5/5 [00:04<00:00,  1.15it/s]","output_type":"stream"},{"name":"stdout","text":"Average F2: 0.12698412698412698\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"submission","metadata":{"execution":{"iopub.status.busy":"2023-03-05T20:07:28.163929Z","iopub.execute_input":"2023-03-05T20:07:28.165443Z","iopub.status.idle":"2023-03-05T20:07:28.182862Z","shell.execute_reply.started":"2023-03-05T20:07:28.165382Z","shell.execute_reply":"2023-03-05T20:07:28.181139Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"         topic_id                                        content_ids\n0  t_00004da3a1b2                                     c_c677789a0df4\n1  t_00068291e9a4  c_88b5b091fd7b c_e6df0d885284 c_52dfafd40731 c...\n2  t_00069b63a70a  c_02436b17b918 c_3695c5dc1df6 c_8577c06c226a c...\n3  t_0006d41a73a8                                     c_29117d57eff7\n4  t_4054df11a74e  c_52f9df7e611a c_3695c5dc1df6 c_8577c06c226a c...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>topic_id</th>\n      <th>content_ids</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>t_00004da3a1b2</td>\n      <td>c_c677789a0df4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>t_00068291e9a4</td>\n      <td>c_88b5b091fd7b c_e6df0d885284 c_52dfafd40731 c...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>t_00069b63a70a</td>\n      <td>c_02436b17b918 c_3695c5dc1df6 c_8577c06c226a c...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>t_0006d41a73a8</td>\n      <td>c_29117d57eff7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>t_4054df11a74e</td>\n      <td>c_52f9df7e611a c_3695c5dc1df6 c_8577c06c226a c...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"submission.to_csv('/kaggle/working/submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2023-03-05T20:08:00.210507Z","iopub.execute_input":"2023-03-05T20:08:00.211029Z","iopub.status.idle":"2023-03-05T20:08:00.225632Z","shell.execute_reply.started":"2023-03-05T20:08:00.210963Z","shell.execute_reply":"2023-03-05T20:08:00.224046Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}